{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import operator\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pyspark\n",
    "from operator import add\n",
    "import numpy as np\n",
    "import matplotlib.path as mplPath\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_geojson(filename,data):\n",
    "    import json\n",
    "    coordinatesList = {}\n",
    "    with open ('block-groups-polygons.geojson') as dataFile:\n",
    "        blockData = json.load(dataFile)\n",
    "    count = 0\n",
    "    for i in data:\n",
    "        for block in blockData['features']:\n",
    "            if i == block['properties']['OBJECTID']:\n",
    "                coordinatesList[count] = [block['geometry'],block['properties']]\n",
    "                count+=1\n",
    "\n",
    "    template = \\\n",
    "        ''' \\\n",
    "        { \"type\" : \"Feature\",\n",
    "            \"id\" : %s,\n",
    "            \"properties\" : %s,\n",
    "            \"geometry\" : %s\n",
    "            },\n",
    "        '''\n",
    "\n",
    "    # the head of the geojson file\n",
    "    output = \\\n",
    "        ''' \\\n",
    "    { \"type\" : \"FeatureCollection\",\n",
    "        \"features\" : [\n",
    "        '''\n",
    "\n",
    "    for k,v in coordinatesList.iteritems():\n",
    "        output += template % (k,json.dumps(v[1]),json.dumps(v[0]))\n",
    "\n",
    "    # the tail of the geojson file\n",
    "    output += \\\n",
    "        ''' \\\n",
    "        ]\n",
    "    }\n",
    "        '''\n",
    "\n",
    "    # opens an geoJSON file to write the output to\n",
    "    outFileHandle = open(filename+\".geojson\", \"w\")\n",
    "    outFileHandle.write(output)\n",
    "    outFileHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def indexZones(shapeFilename):\n",
    "    import rtree\n",
    "    import fiona.crs\n",
    "    import geopandas as gpd\n",
    "    index = rtree.Rtree()\n",
    "    zones = gpd.read_file(shapeFilename).to_crs(fiona.crs.from_epsg(2263))\n",
    "    for idx,geometry in enumerate(zones.geometry):\n",
    "        index.insert(idx, geometry.bounds)\n",
    "    return (index, zones)\n",
    "\n",
    "def findBlock(p, index, zones):\n",
    "    match = index.intersection((p.x, p.y, p.x, p.y))\n",
    "    for idx in match:\n",
    "        z = mplPath.Path(np.array(zones.geometry[idx].exterior))\n",
    "        if z.contains_point(np.array(p)):\n",
    "            return zones['OBJECTID'][idx]\n",
    "    return -1\n",
    "\n",
    "def findB(p, index, zones):\n",
    "    match = index.intersection((p.x, p.y, p.x, p.y))\n",
    "    for idx in match:\n",
    "        if any(map(lambda x: x.contains(p), zones.geometry[idx])):\n",
    "            return zones['boroname'][idx]\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapToZone(parts):\n",
    "    import pyproj\n",
    "    import shapely.geometry as geom\n",
    "    proj = pyproj.Proj(init=\"epsg:2263\", preserve_units=True)    \n",
    "    index, zones = indexZones('block-groups-polygons-simple.geojson')\n",
    "    index2, zones2 = indexZones('boroughs.geojson')\n",
    "    for line in parts:\n",
    "        if line.startswith('vendor_id'): continue \n",
    "        fields = line.strip('').split(',')\n",
    "        if fields ==['']: continue\n",
    "        if all((fields[5],fields[6],fields[9],fields[10])) and float(fields[4])<=2:\n",
    "            pickup_location  = geom.Point(proj(float(fields[5]), float(fields[6])))\n",
    "            dropoff_location = geom.Point(proj(float(fields[9]), float(fields[10])))\n",
    "            pickup_block = findBlock(pickup_location, index, zones)\n",
    "            dropoff_block = findBlock(dropoff_location, index, zones)\n",
    "            pickup_borough = findB(pickup_location, index2, zones2)\n",
    "            dropoff_borough = findB(dropoff_location, index2, zones2)\n",
    "            if pickup_block>=0 and pickup_borough>0 and dropoff_block>0 and dropoff_borough>0:#np.array(pickup_block.exterior)\n",
    "                yield (pickup_block,pickup_borough,dropoff_block,dropoff_borough)\n",
    "                \n",
    "                \n",
    "def mapper2(k2v2):\n",
    "    from heapq import nlargest\n",
    "    k, values = k2v2\n",
    "    top10 = nlargest(10, values, lambda x:x[1])\n",
    "    return (k,top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9099, u'Manhattan', 9203, u'Manhattan'), (9036, u'Manhattan', 9603, u'Manhattan'), (9101, u'Manhattan', 9553, u'Manhattan'), (8986, u'Manhattan', 9427, u'Manhattan'), (8992, u'Manhattan', 9620, u'Manhattan'), (9085, u'Manhattan', 10178, u'Manhattan'), (9486, u'Manhattan', 8983, u'Manhattan'), (10170, u'Manhattan', 9590, u'Manhattan'), (9591, u'Manhattan', 9530, u'Manhattan'), (9436, u'Manhattan', 9601, u'Manhattan')]\n",
      "2.18647948503\n"
     ]
    }
   ],
   "source": [
    "# if __name__=='__main__':\n",
    "#     if len(sys.argv)<3:\n",
    "#         print \"Usage: <input files> <output path>\"\n",
    "#         sys.exit(-1)\n",
    "\n",
    "#sc = pyspark.SparkContext()\n",
    "#     trips = sc.textFile(','.join(sys.argv[1:-1]))\n",
    "trips = sc.textFile('/home/dc/Desktop/Big Data/codes/final project/yellow_tripdata_2011-05.csv')\n",
    "\n",
    "output = sc.parallelize(mapToZone(trips.take(20000)))\n",
    "print output.take(10)\n",
    "print (time.time()-start)/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "pickup = output.map(lambda x: ((x[0],x[1]),1)).reduceByKey(lambda x,y: x+y).map(lambda x:(x[0][1], (x[0][0],x[1]))).groupByKey().map(mapper2)\n",
    "pickup.collect()\n",
    "dropoff = output.map(lambda x: ((x[2],x[3]),1)).reduceByKey(lambda x,y: x+y).map(lambda x:(x[0][1], (x[0][0],x[1]))).groupByKey().map(mapper2)\n",
    "# print dropoff.collect()\n",
    "# print (time.time()-start)/60.0\n",
    "\n",
    "# pickup_all.union(dropff_all)\n",
    "\n",
    "#print final.collect()\n",
    "#final.saveAsTextFile(sys.argv[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Bronx',\n",
       "  [(5387, 1),\n",
       "   (5267, 1),\n",
       "   (5888, 1),\n",
       "   (5396, 1),\n",
       "   (5609, 1),\n",
       "   (5357, 1),\n",
       "   (5389, 1),\n",
       "   (5513, 1)]),\n",
       " (u'Manhattan',\n",
       "  [(9144, 190),\n",
       "   (9245, 153),\n",
       "   (8986, 135),\n",
       "   (9052, 132),\n",
       "   (9493, 122),\n",
       "   (9023, 85),\n",
       "   (9088, 84),\n",
       "   (9509, 80),\n",
       "   (9139, 73),\n",
       "   (9594, 67)]),\n",
       " (u'Brooklyn',\n",
       "  [(12755, 8),\n",
       "   (12164, 7),\n",
       "   (12048, 3),\n",
       "   (11708, 3),\n",
       "   (12756, 3),\n",
       "   (11332, 3),\n",
       "   (12041, 3),\n",
       "   (12049, 3),\n",
       "   (11297, 3),\n",
       "   (12730, 3)]),\n",
       " (u'Queens',\n",
       "  [(2281, 31),\n",
       "   (2371, 6),\n",
       "   (3722, 5),\n",
       "   (2282, 4),\n",
       "   (2252, 3),\n",
       "   (3027, 2),\n",
       "   (3030, 2),\n",
       "   (3164, 2),\n",
       "   (3711, 1),\n",
       "   (2167, 1)])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickup.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create_geojson(\"pickup_map\",pickup_all.map(lambda x: x[1][0]).collect())\n",
    "# create_geojson(\"dropoff_map\",pickup_all.map(lambda x: x[1][0]).collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a = sc.parallelize([(1,2),(3,4)])\n",
    "# b = sc.parallelize([(1,2),(3,4)])\n",
    "# c = a.union(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
