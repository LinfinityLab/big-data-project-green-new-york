{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import operator\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pyspark\n",
    "from operator import add\n",
    "import numpy as np\n",
    "import matplotlib.path as mplPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_geojson(filename,data):\n",
    "    import json\n",
    "    coordinatesList = {}\n",
    "    with open ('block-groups-polygons.geojson') as dataFile:\n",
    "        blockData = json.load(dataFile)\n",
    "    count = 0\n",
    "    for i in data:\n",
    "        for block in blockData['features']:\n",
    "            if i == block['properties']['OBJECTID']:\n",
    "                coordinatesList[count] = [block['geometry'],block['properties']]\n",
    "                count+=1\n",
    "\n",
    "    template = \\\n",
    "        ''' \\\n",
    "        { \"type\" : \"Feature\",\n",
    "            \"id\" : %s,\n",
    "            \"properties\" : %s,\n",
    "            \"geometry\" : %s\n",
    "            },\n",
    "        '''\n",
    "\n",
    "    # the head of the geojson file\n",
    "    output = \\\n",
    "        ''' \\\n",
    "    { \"type\" : \"FeatureCollection\",\n",
    "        \"features\" : [\n",
    "        '''\n",
    "\n",
    "    for k,v in coordinatesList.iteritems():\n",
    "        output += template % (k,json.dumps(v[1]),json.dumps(v[0]))\n",
    "\n",
    "    # the tail of the geojson file\n",
    "    output += \\\n",
    "        ''' \\\n",
    "        ]\n",
    "    }\n",
    "        '''\n",
    "\n",
    "    # opens an geoJSON file to write the output to\n",
    "    outFileHandle = open(filename+\".geojson\", \"w\")\n",
    "    outFileHandle.write(output)\n",
    "    outFileHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def indexZones(shapeFilename):\n",
    "    import rtree\n",
    "    import fiona.crs\n",
    "    import geopandas as gpd\n",
    "    index = rtree.Rtree()\n",
    "    zones = gpd.read_file(shapeFilename).to_crs(fiona.crs.from_epsg(2263))\n",
    "    for idx,geometry in enumerate(zones.geometry):\n",
    "        index.insert(idx, geometry.bounds)\n",
    "    return (index, zones)\n",
    "\n",
    "def findBlock(p, index, zones):\n",
    "    match = index.intersection((p.x, p.y, p.x, p.y))\n",
    "    for idx in match:\n",
    "        z = mplPath.Path(np.array(zones.geometry[idx].exterior))\n",
    "        if z.contains_point(np.array(p)):\n",
    "            return zones['OBJECTID'][idx]\n",
    "    return -1\n",
    "\n",
    "def findB(p, index, zones):\n",
    "    match = index.intersection((p.x, p.y, p.x, p.y))\n",
    "    for idx in match:\n",
    "        if any(map(lambda x: x.contains(p), zones.geometry[idx])):\n",
    "            return zones['boroname'][idx]\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapToZone(parts):\n",
    "    import pyproj\n",
    "    import shapely.geometry as geom\n",
    "    proj = pyproj.Proj(init=\"epsg:2263\", preserve_units=True)    \n",
    "    index, zones = indexZones('block-groups-polygons-simple.geojson')\n",
    "    index2, zones2 = indexZones('boroughs.geojson')\n",
    "    for line in parts:\n",
    "        if line.startswith('vendor_id'): continue \n",
    "        fields = line.strip('').split(',')\n",
    "        if fields ==['']: continue\n",
    "        if all((fields[5],fields[6],fields[9],fields[10])) and float(fields[4])<=2:\n",
    "            pickup_location  = geom.Point(proj(float(fields[5]), float(fields[6])))\n",
    "            dropoff_location = geom.Point(proj(float(fields[9]), float(fields[10])))\n",
    "            pickup_block = findBlock(pickup_location, index, zones)\n",
    "            dropoff_block = findBlock(dropoff_location, index, zones)\n",
    "            pickup_borough = findB(pickup_location, index2, zones2)\n",
    "            dropoff_borough = findB(dropoff_location, index2, zones2)\n",
    "            if pickup_block>=0 and pickup_borough>0 and dropoff_block>0 and dropoff_borough>0:#np.array(pickup_block.exterior)\n",
    "                yield (pickup_block,pickup_borough,dropoff_block,dropoff_borough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((9085, u'Manhattan'), 1), ((9101, u'Manhattan'), 1), ((9099, u'Manhattan'), 1), ((9036, u'Manhattan'), 1), ((8986, u'Manhattan'), 1), ((8992, u'Manhattan'), 1)]\n",
      "[((9553, u'Manhattan'), 1), ((9203, u'Manhattan'), 1), ((9427, u'Manhattan'), 1), ((9603, u'Manhattan'), 1), ((9620, u'Manhattan'), 1), ((10178, u'Manhattan'), 1)]\n"
     ]
    }
   ],
   "source": [
    "# if __name__=='__main__':\n",
    "#     if len(sys.argv)<3:\n",
    "#         print \"Usage: <input files> <output path>\"\n",
    "#         sys.exit(-1)\n",
    "\n",
    "#sc = pyspark.SparkContext()\n",
    "#     trips = sc.textFile(','.join(sys.argv[1:-1]))\n",
    "trips = sc.textFile('/home/satya/BDM_dataset/yellow_tripdata_2011-05.csv')\n",
    "\n",
    "output = sc.parallelize(mapToZone(trips.take(10)))\n",
    "pickup = output.map(lambda x: ((x[0],x[1]),1)).reduceByKey(lambda x,y: x+y)\n",
    "pickup_M = pickup.filter(lambda x: x[0][1] == \"Manhattan\").takeOrdered(10, lambda x: -x[1])\n",
    "pickup_Q = pickup.filter(lambda x: x[0][1] == \"Queens\").takeOrdered(10, lambda x: -x[1])\n",
    "pickup_Bx = pickup.filter(lambda x: x[0][1] == \"Bronx\").takeOrdered(10, lambda x: -x[1])\n",
    "pickup_Bk = pickup.filter(lambda x: x[0][1] == \"Brooklyn\").takeOrdered(10, lambda x: -x[1])\n",
    "pickup_SI = pickup.filter(lambda x: x[0][1] == \"Staten Island\").takeOrdered(10, lambda x: -x[1])\n",
    "pickup_all = sc.parallelize(pickup_M+pickup_Q+pickup_Bx+pickup_Bk+pickup_SI)\n",
    "\n",
    "dropoff = output.map(lambda x: ((x[2],x[3]),1)).reduceByKey(lambda x,y: x+y)\n",
    "dropoff_M = dropoff.filter(lambda x: x[0][1] == \"Manhattan\").takeOrdered(10, lambda x: -x[1])\n",
    "dropoff_Q = dropoff.filter(lambda x: x[0][1] == \"Queens\").takeOrdered(10, lambda x: -x[1])\n",
    "dropoff_Bx = dropoff.filter(lambda x: x[0][1] == \"Bronx\").takeOrdered(10, lambda x: -x[1])\n",
    "dropoff_Bk = dropoff.filter(lambda x: x[0][1] == \"Brooklyn\").takeOrdered(10, lambda x: -x[1])\n",
    "dropoff_SI = dropoff.filter(lambda x: x[0][1] == \"Staten Island\").takeOrdered(10, lambda x: -x[1])\n",
    "dropoff_all = sc.parallelize(dropoff_M+dropoff_Q+dropoff_Bx+dropoff_Bk+dropoff_SI)\n",
    "\n",
    "print pickup_all.collect()\n",
    "print dropoff_all.collect()\n",
    "#print final.collect()\n",
    "#final.saveAsTextFile(sys.argv[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_geojson(\"pickup_map\",pickup_all.map(lambda x: x[0][0]).collect())\n",
    "create_geojson(\"dropoff_map\",pickup_all.map(lambda x: x[0][0]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
